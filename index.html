<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #a61717;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="img/icon.png">
  <title>Joon Kim</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Joon Kim</name>
        </p>
        <p>I am a PhD student in <a href="http://ml.cmu.edu/">Machine Learning Department</a> at <a href="https://www.cmu.edu/">Carnegie Mellon University</a>, advised by Professor <a href="https://www.cs.cmu.edu/~atalwalk/">Ameet Talwalkar</a>. 
        I am interested in studying methods that can assist our understanding of complex machine learning models, and their implications on human interpretability and fairness.</p>
        <p>
          Prior to joining CMU, I received a Bachelors of Science degree in Computer Science at <a href="http://www.caltech.edu">Caltech</a>.
        </p>
        <p align=center>
          <a href="mailto:joonkim@cmu.edu">Email</a> &nbsp/&nbsp
          <a href="docs/CV.pdf">CV</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=H5EeUmgAAAAJ&hl=en"> GoogleScholar </a>
        </p>
        </td>
        <td width="33%">
        <img src="img/profile.png" width="100%">
        </td>
      </tr>
  </table>

<!-- RESEARCH SECTION
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p> I am interested in studying methods that can facilitate our understanding of complex models, and their implications on interpretability and fairness.</p>
        </td>
      </tr>
      </table> -->

<!-- NEWS
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Updates</heading>
          <p> </p>
        </td>
      </tr>
      </table>
-->

<!-- PUBLICATION SECTION -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Publications</heading>
        </td>
      </tr>
      </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <!--SMERF -->
    <tr>
      <td width="25%">
        <img src="img/smerf.png" width="100%">
      </td>
      <td valign="top" width="75%">
        <p><a href="https://arxiv.org/abs/2105.06506">
        <papertitle>Sanity Simulations for Saliency Methods</papertitle></a><br>
        <strong>Joon Sik Kim</strong>, Gregory Plumb, Ameet Talwalkar<br>
        <em>International Conference on Machine Learning (ICML)</em>, 2022.<br>
        <em>XAI4CV Workshop, CVPR </em> 2022.<br>
        <a href="">proceedings</a>
        /
        <a href="">blog post</a>
        /
        <a href="">slides</a>
        /
        <a href="docs/cvpr22_poster_smerf.pdf">poster</a>
        /
        <a href="https://github.com/wnstlr/SMERF">code</a>
        <p>We propose a benchmark study on the limitations of leading saliency methods via several stylized tests of identifying correct sets of features based on different model reasoning.</p>
      </td>
    </tr>


      <!-- Interpretabiliy white paper -->
    <tr>
      <td width="25%">
        <img src="img/whitepaper.png" width="100%">
      </td>
      <td valign="top" width="75%">
        <p><a href="https://arxiv.org/abs/2103.06254">
        <papertitle>Interpretable Machine Learning: Moving From Mythos to Diagnostics</papertitle></a><br>
        Valerie Chen*, Jeffrey Li*, <strong>Joon Sik Kim</strong>**, Gregory Plumb**, Ameet Talwalkar<br>
        <em>ACM Queue. Vol. 19 Issue. 6, November-December 2021.</em><br>
        <em>Workshop on Human in the Loop Learning (HILL), ICML </em>2021.<br>
        <a href="https://dl.acm.org/doi/10.1145/3511299">proceedings</a>
        <p>We survey the current landscape of a field of interpretable machine learning and ways to concretely address existing issues and disconnects.</p>
      </td>
    </tr>

    <!-- TopLayer -->
    <tr>
      <td width="25%">
        <img src="img/toplayer.png" width="100%">
      </td>
      <td valign="top" width="75%">
        <p><a href="https://arxiv.org/abs/2002.02778">
        <papertitle>Efficient Topological Layer based on Persistence Landscape</papertitle></a><br>
        Jisu Kim, Kwangho Kim, Manzil Zaheer, <strong>Joon Sik Kim</strong>, Frederic Chazal, Larry Wasserman<br>
        <em>Neural Information Processing Systems (NeurIPS)</em>, 2020.<br>
		<a href="https://papers.nips.cc/paper/2020/hash/b803a9254688e259cde2ec0361c8abe4-Abstract.html">proceedings</a> 
        /
        <a href="https://github.com/jisuk1/pllay/">code</a>
        <p>We introduce a novel topological layer for deep neural networks based on persistent landscapes, which is able to efficiently capture underlying toplogical feautres of the input data, with stronger stability guarantees.</p>
      </td>
    </tr>

    <!-- Fairness tradeoff -->
    <tr>
      <td width="25%">
        <img src='img/fair-tradeoff2.png' width="100%">
      </td>
      <td valign="top" width="75%">
        <p><a href="https://arxiv.org/abs/2004.03424">
        <papertitle>FACT: A Diagnostic for Group Fairness Trade-offs</papertitle></a><br>
        <strong>Joon Sik Kim</strong>, Jiahao Chen, Ameet Talwalkar <br>
        <em>International Conference on Machine Learning (ICML)</em>, 2020.<br>
		<a href ="http://proceedings.mlr.press/v119/kim20a.html">proceedings</a>
        /
		<a href ="https://blog.ml.cmu.edu/2020/10/12/fact-diagnostic-how-to-better-understand-trade-offs-involving-group-fairness/">blog post</a>
        /
		<a href ="https://www.dropbox.com/s/bf6pwng6t1whnjx/icml2020-fairness.key?dl=0">slides</a>
        /
        <a href ="https://github.com/wnstlr/FACT">code</a>
 		<p></p>
        <p>We proposed a general framework of understanding and diagnosing different types of trade-offs in group fairness, deriving new incompatibility conditions and post-processing method for fair classification.</p>
      </td>
    </tr>

    <!-- Automated Dependence Plot -->
    <tr>
      <td width="25%">
        <img src='img/diagnostic.png' width="100%">
      </td>
      <td valign="top" width="75%">
        <p><a href="https://arxiv.org/abs/1912.01108">
        <papertitle>Automated Dependence Plots</papertitle></a><br>
        David Inouye, Leqi Liu, <strong>Joon Sik Kim</strong>, Bryon Aragam, Pradeep Ravikumar <br>
        <em>Uncertainty in Artificial Intelligence (UAI)</em>, 2020.<br>
        <em>Safety and Robustness in Decision Making Workshop, NeurIPS 2019.</em> <br>
        <a href ="http://proceedings.mlr.press/v124/inouye20a.html">proceedings</a>
        /
        <a href ="https://github.com/davidinouye/adp">code</a>
        <p></p>
        <p>We introduce a framework for automating a search for a partial dependence plot which best captures certain types of model behaviors, encoded with customizable utility functions.</p>
      </td>
    </tr>

    <!-- Representer Points -->
    <tr>
      <td width="25%">
        <img src='img/representer.png' width="100%">
      </td>
      <td valign="top" width="75%">
        <p><a href="https://arxiv.org/abs/1811.09720">
		    <papertitle>Representer Point Selection for Explaining Deep Neural Networks</papertitle></a><br>
		    Chih-kuan Yeh*, <strong>Joon Sik Kim</strong>*, Ian E.H. Yen, Pradeep Ravikumar <br>
		    <em>Neural Information Processing Systems (NeurIPS)</em>, 2018 <br>
		    <a href ="https://papers.nips.cc/paper/8141-representer-point-selection-for-explaining-deep-neural-networks.pdf">proceedings</a>
            /
		    <a href ="https://blog.ml.cmu.edu/2019/04/19/representer-point-selection-explain-dnn/">blog post</a>
            /
		    <a href ="https://github.com/wnstlr/Representer-Point-Poster/blob/master/poster.pdf">poster</a>
            /
        <a href ="https://github.com/chihkuanyeh/Representer_Point_Selection">code</a>
 		    <p></p>
		    <p>We propose a method that decomposes a deep neural network prediction into a linear combination of activation values of training points, in which the weights (called representer values) allow intuitive interpreation of the prediction.</p>
		  </td>
		</tr>

    <!-- Rotation Invariant LFA -->
    <tr>
      <td width="25%">
        <img src='img/rotation.png' width="100%">
      </td>
      <td valign="top" width="75%">
        <p><a href="https://arxiv.org/abs/1609.07495">
		    <papertitle>A Rotation Invariant Latent Factor Model for Moveme Discovery from Static Poses</papertitle></a><br>
		    Matteo Ruggero Ronchi, <strong>Joon Sik Kim</strong>, Yisong Yue <br>
		    <em>IEEE International Conference on Data Mining (ICDM)</em>, 2016 <br>
		    <a href ="https://www.computer.org/csdl/pds/api/csdl/proceedings/download-article/12OmNAsBFPE/pdf">proceedings</a>
            /
		    <a href ="http://www.vision.caltech.edu/~mronchi/projects/RotationInvariantMovemes/">project page</a>
            /
		    <a href ="docs/ICDM16_final.pdf">slides</a>
            /
		    <a href ="docs/scmls_poster.pdf">poster</a>
            /
            <a href ="https://github.com/matteorr/rotation_invariant_movemes">code</a>
            /
            <a href="https://github.com/matteorr/rotation_invariant_movemes/tree/master/inputs">dataset</a>
 		    <p></p>
		    <p> We propose a method to discover a set of rotation-invariant 3-D basis poses that can characterize the manifold of primitive human motions, from a training set of 2-D projected poses obtained from still images taken at various camera angles.</p>
		  </td>
		</tr>
  </table>

<!-- Preprints / Workshops -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
    <td>
    <heading>Preprints/Workshops</heading>
    </td>
    </tr>
    </table>
    <table width="100%" align="center" border="0" cellpadding="20">
    <!--BIC -->
    <tr>
      <td width="25%">
        <img src="img/bic.png" width="100%">
      </td>
      <td valign="top" width="75%">
        <p><a href="https://arxiv.org/abs/2112.06283">
        <papertitle>Bayesian Persuasion for Algorithmic Recourse</papertitle></a><br>
        Keegan Harris, Valerie Chen, <strong>Joon Sik Kim</strong>, Ameet Talwalkar, Hoda Heidari, Zhiwei Steven Wu<br>
        <em>Workshop on Human and Machine Decision, NeurIPS 2021. (Oral Presentation)</em><br>
        <a href="">code</a>
        <p>We study the problem of offering algorithmic recourse without requiring full transparency about the model and how a decision maker can incentivize mutually beneficial action to the decision subjects.</p>
      </td>
    </tr>
    </table>

<!-- TEACHING SECTION -->
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Teaching</heading>
        </td>
      </tr>
      </table>
      <table width="75%" align="center" border="0" cellpadding="20">
      <tr>
        <p>
          <a href="http://kangeunsu.com/creativeai19f/">
          10737 Creative AI - Fall 2019
          </a>
          <br><br>
        </p>

      </tr>
      </table>


      <table width="100%" align="left" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <p align="left">
          <font size="2">
          <a href="https://jonbarron.info/">template courtesy of</a>
	    </font>
        </p>
        </td>
      </tr>
      </table>
      <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-7580334-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
    </td>
    </tr>
  </table>

  </body>
</html>
